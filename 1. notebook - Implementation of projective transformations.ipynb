{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of projective transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will implement algorithms for determining projective transformation for given original points (at least 4 points) and their images. \n",
    "<br/><br/>\n",
    "Firstly, we will implement **naive algorithm**. It's based on composition of two transformations: inverted transformation from *basic points* (points with coordinates (1,0,0), (0,1,0), (0,0,1), (1,1,1)) to originals and transformation from basic points to images. They applied together are actually just this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inits\n",
    "names = ['A', 'B', 'C', 'D']\n",
    "coords = ['1. coordinate ', '2. coordinate ', '3. coordinate ']\n",
    "points_originals = []\n",
    "points_pictures  = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility method for entering points\n",
    "# arguments: \n",
    "#    - msg -- global message for whole input of points\n",
    "#    - foreach_msg -- message for each point\n",
    "#    - list of names of given points\n",
    "def input_points(msg, foreach_msg, names = names):\n",
    "    points = []\n",
    "    print(msg)\n",
    "    \n",
    "    for point in names:\n",
    "        print(foreach_msg, end = \" \")\n",
    "        print(\"{} \".format(point))\n",
    "        first_c = float(input(coords[0]))\n",
    "        second_c = float(input(coords[1]))\n",
    "        third_c = float(input(coords[2]))\n",
    "    \n",
    "        points.append([first_c, second_c, third_c])\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Enter input points: \n",
      "* POINT A \n",
      "1. coordinate 1\n",
      "2. coordinate 2\n",
      "3. coordinate 3\n",
      "* POINT B \n",
      "1. coordinate 3\n",
      "2. coordinate 2\n",
      "3. coordinate 1\n",
      "* POINT C \n",
      "1. coordinate 0\n",
      "2. coordinate 1\n",
      "3. coordinate 1\n",
      "* POINT D \n",
      "1. coordinate 7\n",
      "2. coordinate 11\n",
      "3. coordinate 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1.0, 2.0, 3.0], [3.0, 2.0, 1.0], [0.0, 1.0, 1.0], [7.0, 11.0, 10.0]]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we enter original points\n",
    "points_originals = input_points(\"   Enter input points: \",\n",
    "                                \"* POINT\")\n",
    "points_originals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Now enter appropriate images of these points\n",
      "* IMAGE OF POINT A \n",
      "1. coordinate -2\n",
      "2. coordinate -1\n",
      "3. coordinate 1\n",
      "* IMAGE OF POINT B \n",
      "1. coordinate 2\n",
      "2. coordinate -1\n",
      "3. coordinate 1\n",
      "* IMAGE OF POINT C \n",
      "1. coordinate 2\n",
      "2. coordinate 1\n",
      "3. coordinate 1\n",
      "* IMAGE OF POINT D \n",
      "1. coordinate -2\n",
      "2. coordinate 1\n",
      "3. coordinate 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[-2.0, -1.0, 1.0], [2.0, -1.0, 1.0], [2.0, 1.0, 1.0], [-2.0, 1.0, 1.0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we enter images of points\n",
    "points_pictures = input_points(\"    Now enter appropriate images of these points\",\n",
    "                                \"* IMAGE OF POINT\")\n",
    "points_pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_originals = [[-3.0, -1.0, 1.0], [3.0, -1.0, 1.0], [1.0, 1.0, 1.0], [-1.0, 1.0, 1.0]]\n",
    "points_pictures  = [[-2.0, -1.0, 1.0], [2.0, -1.0, 1.0], [2.0, 1.0, 1.0], [-2.0, 1.0, 1.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_plot(points_originals, points_pictures):\n",
    "    fig = plt.figure(figsize= (10,10))\n",
    "    f1 = fig.add_subplot(221)\n",
    "    points_originals_x = [e[0] for e in points_originals]\n",
    "    points_originals_y = [e[1] for e in points_originals]\n",
    "    f1.scatter(points_originals_x, points_originals_y, marker='o' , \n",
    "               linewidths= 4)\n",
    "\n",
    "    f2 = fig.add_subplot(222)\n",
    "    points_pictures_x = [e[0] for e in points_pictures]\n",
    "    points_pictures_y = [e[1] for e in points_pictures]\n",
    "    f2.scatter(points_pictures_x, points_pictures_y, marker='o' , \n",
    "               linewidths= 4, color = 'orange')\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualitation of points and their images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_plot(points_originals, points_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeated part of Cramer's rule\n",
    "# utility method for create matrix delta_i, calcuating determinate, finding lambda - i\n",
    "# arguments:\n",
    "#    - matrix of system (coefficients with letters in system)\n",
    "#    - constants (numbers from other side of equations)\n",
    "#    - for witch letter we want to know value (witch lambda, expressed by order number)\n",
    "def lambda_i(matrix_of_system, constants, i):\n",
    "    delta_i = np.transpose(deepcopy(matrix_of_system))\n",
    "    delta_i[i] = constants\n",
    "    delta_i = np.transpose(np.array(delta_i))\n",
    "    \n",
    "    return np.linalg.det(delta_i) / np.linalg.det(np.array(matrix_of_system))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method of whole Cramer's rule, we solve whole system - find values of all 3 lambdas\n",
    "# matrix dimensions: (3x3), constants (1x3)\n",
    "def cramers_rule_3(matrix_of_system, constants):\n",
    "    lambda_1 = lambda_i(matrix_of_system, constants, 0)\n",
    "    lambda_2 = lambda_i(matrix_of_system, constants, 1)\n",
    "    lambda_3 = lambda_i(matrix_of_system, constants, 2)\n",
    "    \n",
    "    return (lambda_1, lambda_2, lambda_3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we find projection transformation witch\n",
    "# maps from base points ((1,0,0), (0,1,0), (0,0,1), (1,1,1))\n",
    "# to points given as argument (ALWAYS 4 points!)\n",
    "def projection_transformation_from_base(points):\n",
    "    matrix_of_system = np.array(points[:-1])\n",
    "    matrix_of_system = np.transpose(matrix_of_system)\n",
    "    lambdas = cramers_rule_3(matrix_of_system, points[-1])\n",
    "    transformation = []\n",
    "    \n",
    "    for i in range(0,3):\n",
    "        transformation.append([lambdas[i] * coordinate for coordinate in points[i]])\n",
    "    \n",
    "    return np.transpose(np.array(transformation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we calculate matrix of whole projective transformation\n",
    "# from points_originals to points_pictures like composition\n",
    "# of previous tranformation of points_originals (inverted!) and points_pictures\n",
    "def projection_transformation(points_originals, points_pictures):\n",
    "    g = projection_transformation_from_base(points_originals)\n",
    "    f = projection_transformation_from_base(points_pictures)\n",
    "    \n",
    "    return np.dot(f, np.linalg.inv(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  0.,  0.],\n",
       "       [ 0.,  2., -1.],\n",
       "       [ 0., -1.,  2.]])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix of transformation\n",
    "final_function = projection_transformation(points_originals, points_pictures)\n",
    "final_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DLT - algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive algorithm** for calculating projective transformation for given 4 points and their images isn't bad in terms of time and memory (as its name maybe says), even it's great in this terms. But, it works just for 4 points and uniquely determines transformation. In general case somewhere we will have noise, so it's welcome we have much more given points for greater precision and algorithm which can do with more than 4 points.\n",
    "<br/><br/>\n",
    "Algorithm which can do with arbitrary number of points is **DLT - algorithm**. This is sort of algebraic algorithms based on SVD decomposition which minimizes error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility method for finding rows for big matrix\n",
    "# for each point and its image\n",
    "# Arguments: point (original point) and point_picture (image of original point)\n",
    "# NOTE: We return touple with appropriate rows\n",
    "# (we calculate them by different formulas)\n",
    "def M(point, point_picture):\n",
    "    l1 = [0,0,0,\n",
    "          -point_picture[2] * point[0], \n",
    "          -point_picture[2] * point[1],\n",
    "          -point_picture[2] * point[2],\n",
    "          point_picture[1] * point[0],\n",
    "          point_picture[1] * point[1],\n",
    "          point_picture[1] * point[2]]\n",
    "    \n",
    "    l2 = [point_picture[2] * point[0], \n",
    "          point_picture[2] * point[1],\n",
    "          point_picture[2] * point[2],0,0,0,\n",
    "         -point_picture[0] * point[0], \n",
    "          -point_picture[0] * point[1],\n",
    "          -point_picture[0] * point[2]]\n",
    "    return (l1,l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility method for making big matrix (we will decompose her )\n",
    "# NOTE: We there suppose same number of original points and their images!\n",
    "def A_matrix(points_originals, points_pictures):\n",
    "    A = []\n",
    "    n = len(points_originals)\n",
    "    for i in range(0,n):\n",
    "        hs = M(point=points_originals[i], point_picture=points_pictures[i])\n",
    "        A.append(hs[0])\n",
    "        A.append(hs[1])\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, whole DLT algorithm\n",
    "\n",
    "# **NOTE** : Scaling is temporary disabled!\n",
    "# *****************************************\n",
    "# -----NOTE: We use final output from naive algorithm like valid output\n",
    "# (bad practice in general case)\n",
    "# for scaling on approximately values like them\n",
    "# (this 'damn lambda' in projective transformations)\n",
    "def DLT(points_originals, points_pictures):\n",
    "    A = A_matrix(points_originals, points_pictures) # big matrix\n",
    "    decomposition = np.linalg.svd(np.array(A))  # SVD decomposition of big matrix\n",
    "    \n",
    "    # parsing transformation from v matrix\n",
    "    transformation_ = np.array(decomposition[2][-1]).reshape(3,3)\n",
    "    \n",
    "    #transformation_ = transformation_ * ((final_function[0][0] / transformation_[0][0])) # scaling\n",
    "    return transformation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.34522484e-01,  6.18413875e-17, -2.58635702e-16],\n",
       "       [-5.55111512e-17,  5.34522484e-01, -2.67261242e-01],\n",
       "       [-5.55111512e-17, -2.67261242e-01,  5.34522484e-01]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DLT(points_originals, points_pictures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we found out why is this algorithm better for general usage. With more correspodences we have greater precision, and of course, better results. But still there are some issues.\n",
    "<br/><br/>\n",
    "Not good fact about this algorithm is non-invariance of changes of coordinates (beacuse this is just an algebraic and no geometry algorithm). Solution is doing *normalisation* of coordinates and then transformation won't depend of choice of coordinates. *Normalisation* is composed of determining center of points, its translating to $origin$ and scaling to average distance of origin $\\sqrt{2}$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application to picture processing\n",
    "\n",
    "NOTE: Need to fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_originals = [[354.0,188.0,1.0], [365.0, 314.0, 1.0], [469.0, 254.0, 1.0], [452.0, 113.0, 1.0]]\n",
    "points_pictures  = [[369.0,179.0,1.0], [387.0, 337.0,1.0], [533.0, 334.0, 1.0], [521.0, 151.0,1.0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_pixels(point, img_size):\n",
    "    p = [float(point[0]), float(img_size[1] - point[1]), 1.0]\n",
    "    #p = p.reshape(3,1)\n",
    "    #print(p)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_picture(name):\n",
    "    img_original = Image.open(name)\n",
    "    img_size = img_original.size\n",
    "    img_picture = Image.new('RGB', img_size, 'white')\n",
    "    transform = DLT(points_originals = points_originals, points_pictures=points_pictures)\n",
    "    transform /= transform[0,0]\n",
    "    transform = transform.transpose()\n",
    "    for i in range(0, img_original.size[0]):\n",
    "        for j in range(0, img_original.size[1]):\n",
    "            #from_pixels(point = [i,j], img_size = img_size)\n",
    "            #tp = np.dot(transform, from_pixels(point = [i,j], img_size = img_size))\n",
    "            tp = np.dot([i,j,1], transform)\n",
    "            #tp = tp.reshape(1,3)[0]\n",
    "            #tp = list(tp[0])\n",
    "            \n",
    "            if tp[2] == 0:\n",
    "                continue\n",
    "            tp = [(e / tp[2]) for e in tp]\n",
    "            if math.ceil(tp[0]) < 0 or math.ceil(tp[1]) < 0 or \\\n",
    "            math.ceil(tp[0]) > img_size[0] - 1 or math.ceil(tp[1]) > img_size[1] - 1:\n",
    "                    continue\n",
    "            #tp/= tp[2]\n",
    "            #print(tp)\n",
    "            #print(tp)\n",
    "            #tp = list(tp.reshape(1,3)[0])\n",
    "            #tp = [int(math.ceil(e)) for e in tp]\n",
    "            #print(tp)\n",
    "            #if tp[0] < 0 or img_original.size[1] - tp[1] > 0 or tp[0] >= img_original.size[0] or img_original.size[1] - tp[1] >= img_original.size[1]:\n",
    "            #        continue\n",
    "            #img_size = img_original.size\n",
    "            #img_picture.putpixel((tp[0], img_size[1] - tp[1]), img_original.getpixel((i, j)))\n",
    "            #img_picture.save()\n",
    "            \n",
    "            col = img_original.getpixel((i,j))\n",
    "            img_original.putpixel((math.ceil(tp[0]), math.ceil(tp[1])), col)\n",
    "    return img_picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=600x775 at 0x7FD5F552F048>"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_picture('building.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drugi pokusaj\n",
    "def transform_picture(path):\n",
    "    transformation = DLT(points_originals = points_originals,\n",
    "                         points_pictures  = points_pictures)\n",
    "    \n",
    "    img = Image.open(path)\n",
    "    img_pixels = Image.\n",
    "    \n",
    "    img_picture_pixels = img_pixels\n",
    "    img_picture_pixels.reshape()\n",
    "    img_picture_pixels.fill(255)\n",
    "    \n",
    "    for i in range(0, img_dimensions[1]):\n",
    "        for j in range(0, img_dimensions[0]):\n",
    "            t = np.array([i, img_dimensions[0] - j, 1])\n",
    "            t.reshape(1,3)\n",
    "            transformated_pixel = np.dot(transformation,t)\n",
    "            #print(transformated_pixel)\n",
    "            transformated_pixel /= transformated_pixel[2]\n",
    "            #print(transformated_pixel)\n",
    "            X = int(transformated_pixel[0])\n",
    "            Y = int(transformated_pixel[1])\n",
    "            \n",
    "            if X < 0 or Y  < 0 or X > img_dimensions[0] or Y > img_dimensions[1]:\n",
    "                continue\n",
    "            \n",
    "            img_picture_pixels[X - 1,img_dimensions[1] - 1 - Y,0] = img_pixels[i,j,0]\n",
    "            img_picture_pixels[X - 1,img_dimensions[1] - 1 - Y,1] = img_pixels[i,j,1]\n",
    "            img_picture_pixels[X - 1,img_dimensions[1] - 1 - Y,2] = img_pixels[i,j,2]\n",
    "    \n",
    "    img.close()\n",
    "    return img_picture_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modificated DLT - algorithm (*with normalisation*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Center of points** (in affine coordinates):\n",
    "\n",
    "Formula for determining center of points (equal masses):\n",
    "\n",
    "$$\\sum\\limits_{i = 1}^{n}{\\vec{TAi}} = \\vec{0}$$\n",
    "\n",
    "Further we get\n",
    "\n",
    "$$ \\sum\\limits_{i=1}^{n} \\pmatrix{x_{ai} \\\\ y_{ai}} - \\pmatrix{x_t \\\\ y_t } = \\pmatrix{0 \\\\ 0}$$\n",
    "\n",
    "$$ \\sum\\limits_{i=1}^{n} \\pmatrix{x_{ai} - x_t \\\\ y_{ai} - y_t } = \\pmatrix {0 \\\\ 0 } $$\n",
    "\n",
    "$$ \\sum\\limits_{i=1}^{n} x_{ai} - x_t = 0 ,  \\sum\\limits_{i=1}^{n} y_{ai} - y_t = 0  $$\n",
    " \n",
    "$$ \\sum\\limits_{i=1}^{n} x_{ai} = n * x_t ,  \\sum\\limits_{i=1}^{n} y_{ai} = n * y_t $$\n",
    "\n",
    "So, we at the end get \n",
    "\n",
    "$$ \\frac{\\sum\\limits_{i=1}^{n} x_{ai}}{n} = x_t , \\frac{\\sum\\limits_{i=1}^{n} y_{ai}}{n} = y_t $$\n",
    "\n",
    "$$ \\boxed{x_t = \\overline{x_{ai}}},\\boxed{y_t = \\overline{y_{ai}}} $$\n",
    "\n",
    "We will applicate just this formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility method for determining center of points\n",
    "# points given like two-component touples with affine coordinates\n",
    "def center_of_points(points):\n",
    "    xs = [point[0] for point in points]\n",
    "    ys = [point[1] for point in points]\n",
    "    \n",
    "    return (np.average(xs), np.average(ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaling to average distance of $origin$ $\\sqrt{2}$**\n",
    "\n",
    "Let's $\\sigma$ average distance of $origin$.\n",
    "\n",
    "$$ \\sigma = \\frac{\\sum\\limits_{i=1}^{n}{\\sqrt{x_i^2 + y_i^2}}}{n} $$\n",
    "$$ \\frac{\\sqrt{2}}{\\sigma} * / \\sigma = \\frac{\\sum\\limits_{i=1}^{n}{\\sqrt{x_i^2 + y_i^2}}}{n} $$\n",
    "$$ \\sqrt{2} = \\frac{(\\frac{\\sqrt{2}}{\\sigma})*\\sum\\limits_{i=1}^{n}{\\sqrt{x_i^2 + y_i^2}}}{n} $$\n",
    "$$ \\sqrt{2} = \\frac{\\sum\\limits_{i=1}^{n}{\\sqrt{(\\frac{\\sqrt{2}}{\\sigma})^2*(x_i^2 + y_i^2)}}}{n} $$\n",
    "$$ \\sqrt{2} = \\frac{\\sum\\limits_{i=1}^{n}{\\sqrt{(((\\frac{\\sqrt{2}}{\\sigma})*x_i)^2 + ((\\frac{\\sqrt{2}}{\\sigma})*y_i)^2)}}}{n} $$\n",
    "\n",
    "So we can do scalling with parameter $(\\frac{\\sqrt{2}}{\\sigma})$ to both coordinates. (homotety with coefficient $k=(\\frac{\\sqrt{2}}{\\sigma})$ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility method for calculating scaling matrix (like projective transformation)\n",
    "# points given like two-component touples with affine coordinates\n",
    "# it could be shorter using numpy's properties and some optimizations\n",
    "# but now isn't focus on this\n",
    "def scaling_to_sqrt_2(points): \n",
    "    sigma = 0\n",
    "    for (x,y) in points:\n",
    "        sigma += math.sqrt(x**2 + y**2)\n",
    "    sigma /= (len(points))\n",
    "    k = math.sqrt(2) / sigma\n",
    "    return np.array([[k,0,0], [0,k,0],[0,0,1]]).reshape(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility method for conversion from homogeneous to affine coordinates\n",
    "# points given like three-component touples with homogeneous coordinates\n",
    "# NOTE: We suppose NO INFINITY FAR points in list\n",
    "def get_affine(points):\n",
    "    return [(x[0]/x[2], x[1]/x[2]) for x in points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility method for conversion to homogeneous from affine coordinates\n",
    "# points given like two-component touples with affine coordinates\n",
    "def to_homogenous(points):\n",
    "    return [(x[0], x[1], 1) for x in points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method for whole calculating matrix of normalisation\n",
    "# points given like three-component touples with homogeneous coordinates\n",
    "def normalization(points):\n",
    "    a_points = get_affine(points)\n",
    "    t = center_of_points(a_points)\n",
    "    \n",
    "    # matrix of translation\n",
    "    T = np.array([[1,0,-t[0]],\n",
    "                  [0,1,-t[1]],\n",
    "                  [0,0,1]  ])\n",
    "    S = scaling_to_sqrt_2(a_points)\n",
    "    return np.dot(S, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility method for application got normalization transformation on points\n",
    "# points are given in homogenous coordinates\n",
    "def normalize_points(points):\n",
    "    points_arg = []\n",
    "    N = normalization(points)\n",
    "    \n",
    "    for point in points:\n",
    "        p = np.dot(N,np.array(point).reshape(3,1)).reshape(1,3)[0]\n",
    "        points_arg.append(p)\n",
    "    \n",
    "    return points_arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Whole DLT algorithm with normalization\n",
    "def modified_DLT(points_originals, points_pictures):\n",
    "    N_o = normalization(points_originals)\n",
    "    N_p = normalization(points_pictures)\n",
    "    points_o_norm = normalize_points(points_originals)\n",
    "    points_p_norm = normalize_points(points_pictures)\n",
    "    \n",
    "    P = DLT(points_originals = points_o_norm,\n",
    "            points_pictures  = points_p_norm)\n",
    "    \n",
    "    N_p_inv = np.linalg.inv(N_p)\n",
    "    \n",
    "    return np.dot(np.dot(N_p_inv,P), N_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17244779, -0.53985373,  1.17768421],\n",
       "       [ 0.10144537, -0.04660686,  0.87252043],\n",
       "       [-0.04280793,  0.00713466,  0.88477719]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Totally random values for demonstration\n",
    "modified_DLT([(1,2,3),(-4,5,6)], [(1,1,1), (4,5,6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.09717651e-01,  4.60060610e-17,  1.03645504e-16],\n",
       "       [-5.42453603e-17,  5.09717651e-01, -2.54858825e-01],\n",
       "       [ 1.71538891e-17, -2.54858825e-01,  5.09717651e-01]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test values\n",
    "modified_DLT(points_originals, points_pictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from PIL import Image, ImageTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Tk()  # create a window\n",
    "\n",
    "frame = Frame(root)  # define upper frame\n",
    "middleframe = Frame(root)  # define middle frame\n",
    "exitFrame = Frame(root)  # define exit frame\n",
    "frame.pack()  # pack the frame\n",
    "middleframe.pack()  # pack the subframe\n",
    "exitFrame.pack(side = 'bottom')  # pack the exit frame\n",
    "\n",
    "# function that closes the GUI\n",
    "def close_window(): \n",
    "    root.destroy()\n",
    "\n",
    "# load the image\n",
    "img = PhotoImage(file=\"building.png\")  # save the image\n",
    "panel = Label(frame, image=img)  # display the image as a label\n",
    "panel.grid(row=0, column=0)  # pack the image\n",
    "\n",
    "# make the user select some points\n",
    "global x_Coordinates  # initialize empty list for storing x-axis coordinates\n",
    "global y_Coordinates  # initialize empty list for storing y-axis coordinates\n",
    "x_Coordinates = []\n",
    "y_Coordinates = []\n",
    "\n",
    "clicks = 0\n",
    "def countClicks():\n",
    "    global clicks # this will use the variable to count\n",
    "    clicks = clicks + 1  # increment \"clicks\"\n",
    "    if clicks == 2: # if the user has selected 2 points, add a button that closes the window\n",
    "        exit_button = Button(exitFrame, state = \"normal\", text = \"Done!\", command = close_window)  # link the closing function to the button\n",
    "        exit_button.grid(row=2, column=0, pady=5)  # set button position with \"grid\"        \n",
    "pass\n",
    "\n",
    "def selectPoints():  # function called when user clicks the button \"select two points\"\n",
    "    panel.bind(\"<Button 1>\", saveCoordinates)  #  link the function to the left-mouse-click event\n",
    "    exit_button = Button (exitFrame, state = \"disabled\", text = \"Done!\", command = close_window)  # link closing function to the button\n",
    "    exit_button.grid(row=2, column=0, pady=5)  # set button position with \"grid\"\n",
    "    button_select_points.config(state = \"disabled\") # switch button state to \"disabled\"\n",
    "\n",
    "def saveCoordinates(event): # function called when left-mouse-button is clicked   \n",
    "    x_coordinate = event.x  # save x and y coordinates selected by the user\n",
    "    y_coordinate = event.y\n",
    "   #print(\"X: \", x_coordinate)\n",
    "   #print(\"Y: \", y_coordinate)\n",
    "   #print()\n",
    "   #print(\"----------\")\n",
    "   #print()\n",
    "    x_Coordinates.append(x_coordinate)  # append to external list\n",
    "    y_Coordinates.append(y_coordinate)  # append to external list\n",
    "    countClicks()  # invoke function \"countClicks\"\n",
    "\n",
    "button_select_points = Button(middleframe, text = \"select two points\", command = selectPoints)  # insert button and link it to \"selectPoints\"\n",
    "button_select_points.grid(row=1, column=0, pady=5)  # set button position with \"grid\"\n",
    "\n",
    "root.mainloop()  # keep the GUI open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QLabel\n",
    "from PyQt5.QtGui import QIcon, QPixmap\n",
    "\n",
    "class App(QWidget):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.title = 'PyQt5 image - pythonspot.com'\n",
    "        self.left = 10\n",
    "        self.top = 10\n",
    "        self.width = 640\n",
    "        self.height = 480\n",
    "        self.initUI()\n",
    "    \n",
    "    def initUI(self):\n",
    "        self.setWindowTitle(self.title)\n",
    "        self.setGeometry(self.left, self.top, self.width, self.height)\n",
    "    \n",
    "        # Create widget\n",
    "        label = QLabel(self)\n",
    "        pixmap = QPixmap('image.jpeg')\n",
    "        label.setPixmap(pixmap)\n",
    "        self.resize(pixmap.width(),pixmap.height())\n",
    "        \n",
    "        self.show()\n",
    "\n",
    "\n",
    "app = QApplication(['My application'])\n",
    "ex = App()\n",
    "sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
